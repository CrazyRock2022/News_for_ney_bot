#!/usr/bin/env python3
import os
import sys
import time
import json
import signal
import sqlite3
import feedparser
import aiohttp
import asyncio
import logging
import hashlib
from datetime import datetime, timedelta
from contextlib import contextmanager
from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import Command, CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.client.default import DefaultBotProperties
from aiogram.enums import ParseMode
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from tenacity import retry, stop_after_attempt, wait_exponential

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
load_dotenv()
API_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("newsbot.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(
    token=API_TOKEN,
    default=DefaultBotProperties(parse_mode=ParseMode.HTML)
dp = Dispatcher(storage=MemoryStorage())
scheduler = AsyncIOScheduler()

# –°–æ—Å—Ç–æ—è–Ω–∏—è
class UserState(StatesGroup):
    ADDING_SOURCE = State()
    AWAITING_PROMPT = State()

# –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
@contextmanager
def db_connection():
    conn = sqlite3.connect("newsbot.db")
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def init_db():
    with db_connection() as conn:
        conn.execute("""
        CREATE TABLE IF NOT EXISTS sources (
            url TEXT PRIMARY KEY,
            added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )""")
        conn.execute("""
        CREATE TABLE IF NOT EXISTS sent_links (
            link TEXT PRIMARY KEY,
            sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )""")
        conn.execute("""
        CREATE TABLE IF NOT EXISTS users (
            user_id INTEGER PRIMARY KEY,
            registered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )""")

# –ü–∞—Ä—Å–µ—Ä—ã –¥–ª—è —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
def parse_cryptopanic(entry):
    return {
        "title": entry.get("title", ""),
        "link": entry.get("link", ""),
        "content": f"{entry.get('description', '')} | Currencies: {entry.get('currencies', '')}"
    }

SOURCE_PARSERS = {
    "cryptopanic.com": parse_cryptopanic,
}

# OpenAI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
async def analyze_with_gpt(text: str, prompt: str) -> str:
    try:
        response = await openai.ChatCompletion.acreate(
            model="gpt-4-turbo",
            messages=[{
                "role": "user",
                "content": f"{prompt}\n\n{text[:3000]}\n\n–û—Ç–≤–µ—Ç:"
            }],
            max_tokens=50,
            temperature=0.3
        )
        return response.choices[0].message.content.strip().lower()
    except Exception as e:
        logging.error(f"OpenAI error: {str(e)}")
        return "–Ω–µ—Ç"

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
async def process_feed(url: str):
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    return feedparser.parse(await response.text())
    except Exception as e:
        logging.error(f"Feed error: {str(e)}")
    return None

async def fetch_news(prompt: str):
    relevant = []
    stats = {}
    
    with db_connection() as conn:
        sent_links = {row["link"] for row in conn.execute("SELECT link FROM sent_links")}
        sources = [row["url"] for row in conn.execute("SELECT url FROM sources")]

    for url in sources:
        try:
            feed = await process_feed(url)
            if not feed or not feed.entries:
                continue

            source_name = feed.feed.get("title", url)
            parser = SOURCE_PARSERS.get(url.split("//")[-1].split("/")[0], None)
            
            source_stats = {"total": 0, "relevant": 0}
            for entry in feed.entries[:50]:
                if parser:
                    entry_data = parser(entry)
                else:
                    entry_data = {
                        "title": entry.get("title", ""),
                        "link": entry.get("link", ""),
                        "content": entry.get("description", "")
                    }

                if not entry_data["link"] or entry_data["link"] in sent_links:
                    continue

                source_stats["total"] += 1
                analysis_text = f"{entry_data['title']}\n{entry_data['content']}"
                answer = await analyze_with_gpt(analysis_text, prompt)
                
                if "–¥–∞" in answer:
                    relevant.append((entry_data["title"], entry_data["link"]))
                    sent_links.add(entry_data["link"])
                    source_stats["relevant"] += 1

            stats[source_name] = source_stats
            logging.info(f"Processed {url}: {source_stats}")

        except Exception as e:
            logging.error(f"Error processing {url}: {str(e)}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Å—Å—ã–ª–æ–∫
    if relevant:
        with db_connection() as conn:
            conn.executemany(
                "INSERT OR IGNORE INTO sent_links (link) VALUES (?)",
                [(link,) for _, link in relevant]
            )

    return relevant, stats

# –•–µ–Ω–¥–ª–µ—Ä—ã
@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    with db_connection() as conn:
        conn.execute("INSERT OR IGNORE INTO users (user_id) VALUES (?)", 
                    (message.from_user.id,))
    
    await message.answer(
        "üì∞ –ë–æ—Ç –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –Ω–æ–≤–æ—Å—Ç–µ–π A7A5\n\n"
        "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
        "/digest - –ü–æ–ª—É—á–∏—Ç—å —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏\n"
        "/add_source - –î–æ–±–∞–≤–∏—Ç—å RSS-–∏—Å—Ç–æ—á–Ω–∏–∫\n"
        "/stats - –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
        reply_markup=types.InlineKeyboardMarkup(inline_keyboard=[
            [types.InlineKeyboardButton(text="üÜò –ü–æ–º–æ—â—å", callback_data="help")]
        )
    )

@dp.message(Command("digest"))
async def cmd_digest(message: types.Message, state: FSMContext):
    await message.answer("‚è≥ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –Ω–æ–≤–æ—Å—Ç–∏...")
    try:
        relevant, stats = await fetch_news(DEFAULT_PROMPT)
        report = ["üìä –û—Ç—á—ë—Ç –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:"]
        
        for source, data in stats.items():
            report.append(
                f"‚ñ™Ô∏è {source}: {data['relevant']}/{data['total']} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö"
            )

        if relevant:
            await state.update_data(relevant_news=relevant)
            await message.answer(
                "\n".join(report),
                reply_markup=types.InlineKeyboardMarkup(inline_keyboard=[
                    [types.InlineKeyboardButton(
                        text="üì© –ü–æ–ª—É—á–∏—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ ({len(relevant)})", 
                        callback_data="get_news")]
                )
            )
        else:
            await message.answer("\n".join(report) + "\n\n‚ùå –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

    except Exception as e:
        logging.error(f"Digest error: {str(e)}")
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–æ–≤–æ—Å—Ç–µ–π")

@dp.callback_query(F.data == "get_news")
async def show_news(callback: types.CallbackQuery, state: FSMContext):
    data = await state.get_data()
    news = data.get("relevant_news", [])
    
    for title, link in news:
        await callback.message.answer(f"<b>{title}</b>\n{link}")
    
    await callback.message.edit_reply_markup(reply_markup=None)
    await callback.answer()

@dp.message(Command("add_source"))
async def cmd_add_source(message: types.Message, state: FSMContext):
    await message.answer("–í–≤–µ–¥–∏—Ç–µ URL RSS-–ª–µ–Ω—Ç—ã:")
    await state.set_state(UserState.ADDING_SOURCE)

@dp.message(UserState.ADDING_SOURCE)
async def process_source(message: types.Message, state: FSMContext):
    url = message.text.strip()
    if not url.startswith("http"):
        await message.answer("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL")
        return
    
    try:
        with db_connection() as conn:
            conn.execute("INSERT INTO sources (url) VALUES (?)", (url,))
        await message.answer(f"‚úÖ –ò—Å—Ç–æ—á–Ω–∏–∫ –¥–æ–±–∞–≤–ª–µ–Ω: {url}")
    except sqlite3.IntegrityError:
        await message.answer("‚ö†Ô∏è –≠—Ç–æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    await state.clear()

# –ï–∂–µ–¥–Ω–µ–≤–Ω–∞—è —Ä–∞—Å—Å—ã–ª–∫–∞
async def daily_digest():
    logging.info("Starting daily digest...")
    relevant, _ = await fetch_news(DEFAULT_PROMPT)
    if not relevant:
        return

    with db_connection() as conn:
        users = [row["user_id"] for row in conn.execute("SELECT user_id FROM users")]

    for user_id in users:
        try:
            for title, link in relevant[:5]:
                await bot.send_message(user_id, f"<b>{title}</b>\n{link}")
                await asyncio.sleep(1)
        except Exception as e:
            logging.error(f"Error sending to {user_id}: {str(e)}")

# –ó–∞–ø—É—Å–∫
async def on_shutdown():
    logging.info("Shutting down...")
    await bot.close()

async def main():
    init_db()
    scheduler.add_job(daily_digest, "cron", hour=11)
    scheduler.start()
    
    await bot.delete_webhook()
    await dp.start_polling(bot)

if __name__ == "__main__":
    signal.signal(signal.SIGTERM, lambda s, f: asyncio.run(on_shutdown()))
    asyncio.run(main())